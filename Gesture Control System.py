import cv2
import mediapipe as mp
import pyautogui
import time
import sys
import numpy as np
import math
import ctypes # <-- å¯¼å…¥ ctypes ç”¨äºè°ƒç”¨ Windows API é”å±

# --- æ£€æŸ¥åº“æ˜¯å¦æ­£ç¡®å®‰è£… ---
try:
    print(f"OpenCV Version: {cv2.__version__}")
    print(f"MediaPipe Version: {mp.__version__}")
except AttributeError:
    print("ğŸ”´ é”™è¯¯ï¼šcv2 æˆ– mediapipe åº“æœªæ­£ç¡®åŠ è½½ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ Python ç¯å¢ƒå’Œä¾èµ–ã€‚")
    sys.exit(1)

# --- åˆå§‹åŒ– MediaPipe ---
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,  # åªéœ€æ£€æµ‹ä¸€åªæ‰‹
    min_detection_confidence=0.7, 
    min_tracking_confidence=0.6 
)
mp_drawing = mp.solutions.drawing_utils

# --- åˆå§‹åŒ–æ‘„åƒå¤´ ---
cap = cv2.VideoCapture(0) 
if not cap.isOpened():
    print("ğŸ”´ é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´ã€‚")
    sys.exit(1)

# --- é…ç½®æ§åˆ¶å‚æ•° ---
COOLDOWN_TIME = 1.0  # æ‰‹åŠ¿è§¦å‘å†·å´æ—¶é—´ï¼ˆç§’ï¼‰
last_action_time = time.time() - COOLDOWN_TIME 
scroll_threshold = 0.05 # æ»šåŠ¨è§¦å‘çš„ Y è½´å½’ä¸€åŒ–ç§»åŠ¨é˜ˆå€¼
SCROLL_SPEED = 15      # æ¯æ¬¡æ»šåŠ¨æ“ä½œçš„å¹…åº¦

# æ¨¡å¼æ§åˆ¶çŠ¶æ€
scroll_mode_active = False 
last_scroll_y = 0.5        # ç”¨äºè·Ÿè¸ªé£ŸæŒ‡çš„Yåæ ‡

# æ ¸å¿ƒé˜ˆå€¼ï¼ˆè§’åº¦ï¼‰
STRAIGHT_ANGLE_THRESHOLD = 160 # è§’åº¦å¤§äº 160 åº¦è§†ä¸ºä¼¸ç›´ï¼ˆå››æŒ‡ï¼‰
BENT_ANGLE_THRESHOLD = 150     # æ‹‡æŒ‡çš„è§’åº¦é˜ˆå€¼

# å››æŒ‡çš„å…³é”®ç‚¹åºåˆ—ï¼ˆMCP -> PIP -> TIPï¼‰
FINGER_JOINTS = [
    [5, 6, 8],   # é£ŸæŒ‡
    [9, 10, 12], # ä¸­æŒ‡
    [13, 14, 16], # æ— åæŒ‡
    [17, 18, 20]  # å°æŒ‡
]

# --- æ ¸å¿ƒå‡½æ•°ï¼šè®¡ç®—ä¸‰ç‚¹å¤¹è§’ (ä¿æŒä¸å˜) ---
def calculate_angle(p1, p2, p3):
    p1_coords = np.array([p1.x, p1.y, p1.z])
    p2_coords = np.array([p2.x, p2.y, p2.z])
    p3_coords = np.array([p3.x, p3.y, p3.z])

    vec1 = p1_coords - p2_coords
    vec2 = p3_coords - p2_coords
    
    dot_product = np.dot(vec1, vec2)
    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)
    
    if norm_product == 0:
        return 180.0 
        
    cosine_angle = dot_product / norm_product
    cosine_angle = np.clip(cosine_angle, -1.0, 1.0)
    
    angle_rad = np.arccos(cosine_angle)
    angle_deg = np.degrees(angle_rad)
    
    return angle_deg

# --- æ ¸å¿ƒå‡½æ•°ï¼šåˆ¤æ–­æ‰‹æŒ‡çŠ¶æ€ (ä¿æŒä¸å˜) ---
def is_finger_straight(hand_landmarks, joints, threshold):
    p_mcp = hand_landmarks.landmark[joints[0]]
    p_pip = hand_landmarks.landmark[joints[1]]
    p_tip = hand_landmarks.landmark[joints[2]]
    
    angle = calculate_angle(p_mcp, p_pip, p_tip)
    
    return angle > threshold

# --- æ ¸å¿ƒæ‰‹åŠ¿è¯†åˆ«å‡½æ•°ï¼ˆV11.0 é€»è¾‘ï¼‰ ---
def get_hand_gesture(hand_landmarks):
    
    # å…³é”®ç‚¹ç´¢å¼•å¸¸é‡
    THUMB_CMC = mp_hands.HandLandmark.THUMB_CMC.value 
    THUMB_MP_INDEX = 2 
    THUMB_IP = mp_hands.HandLandmark.THUMB_IP.value 
    
    # 1. åˆ¤æ–­æ‹‡æŒ‡çŠ¶æ€
    thumb_angle = calculate_angle(
        hand_landmarks.landmark[THUMB_CMC],      
        hand_landmarks.landmark[THUMB_MP_INDEX], 
        hand_landmarks.landmark[THUMB_IP]        
    )
    thumb_open = thumb_angle > BENT_ANGLE_THRESHOLD

    # 2. åˆ¤æ–­å››æŒ‡çŠ¶æ€
    finger_states = []
    for joints in FINGER_JOINTS:
        is_open = is_finger_straight(hand_landmarks, joints, STRAIGHT_ANGLE_THRESHOLD)
        finger_states.append(is_open)

    index_open, middle_open, ring_open, pinky_open = finger_states

    # ç»„åˆçŠ¶æ€åˆ—è¡¨
    all_fingers_open = [thumb_open, index_open, middle_open, ring_open, pinky_open]

    # --- æ‰‹åŠ¿é€»è¾‘åˆ¤æ–­ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰---
    
    # âœŒï¸ V_SIGN (å‰ªåˆ€æ‰‹) -> é”å®šå±å¹•
    if not thumb_open and index_open and middle_open and not ring_open and not pinky_open:
        return "V_SIGN"
    
    # ğŸ‘† POINTING (é£ŸæŒ‡ä¼¸å‡º) -> æ»šåŠ¨æ¨¡å¼åˆ‡æ¢
    elif not thumb_open and index_open and not middle_open and not ring_open and not pinky_open:
        return "SCROLL_MODE_TOGGLE"

    # âœ‹ OPEN_HAND (å¼ å¼€æ‰‹æŒ) -> çª—å£æœ€å¤§åŒ– (åŠŸèƒ½æ¢å¤)
    elif all(all_fingers_open):
        return "OPEN_HAND"
        
    # âœŠ CLOSED_FIST (æ¡æ‹³) -> çª—å£ç¼©å°/æœ€å°åŒ–
    elif not index_open and not middle_open and not ring_open and not pinky_open:
         return "CLOSED_FIST"
    
    # ç§»é™¤äº†æ‰€æœ‰å…¶ä»–ä¸ç”¨çš„æ‰‹åŠ¿ï¼Œå¦‚ THUMB_UP
    
    return "UNKNOWN"

# --- æ»šåŠ¨æ§åˆ¶å‡½æ•°ï¼šåŸºäºé£ŸæŒ‡ Y è½´ç§»åŠ¨ (ä¿æŒä¸å˜) ---
def control_scroll_by_index(hand_landmarks):
    global last_scroll_y, SCROLL_SPEED, scroll_threshold
    
    current_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP.value].y
    
    y_diff = current_y - last_scroll_y
    scroll_action = None
    
    if y_diff > scroll_threshold: 
        pyautogui.scroll(-SCROLL_SPEED) 
        scroll_action = "DOWN"
    elif y_diff < -scroll_threshold:
        pyautogui.scroll(SCROLL_SPEED) 
        scroll_action = "UP"

    last_scroll_y = current_y
    return scroll_action
    
# --- ä¸»å¾ªç¯ ---
print("=== V11.0 ç¨³å®šç‰ˆæ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ (çª—å£æœ€å¤§åŒ–æ¢å¤) ===")
print("æ‰‹åŠ¿åŠŸèƒ½è¯´æ˜ï¼š")
print("âœŒï¸ Vå­—æ‰‹åŠ¿ -> **é”å®šå±å¹• (API)**")
print("âœ‹ å¼ å¼€æ‰‹æŒ -> **çª—å£æœ€å¤§åŒ– (win+up)**")
print("âœŠ æ¡æ‹³ (å››æŒ‡å¼¯æ›²) -> çª—å£ç¼©å°/æœ€å°åŒ– (win+down)") 
print("ğŸ‘† é£ŸæŒ‡ä¼¸å‡º -> **æ¨¡å¼åˆ‡æ¢ï¼šæ¿€æ´»/é€€å‡º é£ŸæŒ‡æ»šåŠ¨æ¨¡å¼**")
print("â†”ï¸ (æ»šåŠ¨æ¨¡å¼æ¿€æ´»æ—¶) é£ŸæŒ‡ä¸Šä¸‹ç§»åŠ¨ -> é¡µé¢æ»šåŠ¨")
print("åœ¨è§†é¢‘çª—å£ä¸­æŒ‰ 'q' é”®é€€å‡ºã€‚")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1)
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    results = hands.process(rgb_frame)
    current_time = time.time()
    gesture_detected = False

    hand_landmarks_list = results.multi_hand_landmarks if results.multi_hand_landmarks else []
    
    # --- 1. å•æ‰‹æ‰‹åŠ¿æ£€æµ‹ ---
    if hand_landmarks_list:
        # åªå¤„ç†æ£€æµ‹åˆ°çš„ç¬¬ä¸€åªæ‰‹
        hand_landmarks = hand_landmarks_list[0] 
        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            
        current_gesture = get_hand_gesture(hand_landmarks)

        # --- æ‰‹åŠ¿åŠŸèƒ½æ‰§è¡Œé€»è¾‘ ---
            
        # æ¨¡å¼åˆ‡æ¢æ§åˆ¶ (é£ŸæŒ‡ä¼¸å‡º)
        if current_gesture == "SCROLL_MODE_TOGGLE":
             if current_time - last_action_time > COOLDOWN_TIME:
                scroll_mode_active = not scroll_mode_active
                print(f"ğŸ”„ æ¨¡å¼åˆ‡æ¢ (é£ŸæŒ‡): æ»šåŠ¨æ¨¡å¼ {'å·²æ¿€æ´»' if scroll_mode_active else 'å·²é€€å‡º'}")
                
                if scroll_mode_active:
                     last_scroll_y = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP.value].y
                     
                last_action_time = current_time
                gesture_detected = True
        
        # 1. æ»šåŠ¨æ¨¡å¼æ¿€æ´»æ—¶ï¼Œåªæ‰§è¡Œæ»šåŠ¨æ“ä½œ
        if scroll_mode_active:
            scroll_action = control_scroll_by_index(hand_landmarks)
            if scroll_action:
                cv2.putText(frame, f"SCROLLING: {scroll_action.upper()}", (10, 60), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 0), 2)
            
            current_gesture = "SCROLL_ACTIVE" 

        # 2. æ»šåŠ¨æ¨¡å¼æœªæ¿€æ´»æ—¶ï¼Œæ‰§è¡Œå…¶ä»–å•æ¬¡åŠ¨ä½œï¼ˆå—å†·å´æ—¶é—´é™åˆ¶ï¼‰
        elif current_time - last_action_time > COOLDOWN_TIME and not gesture_detected:
            
            action_performed = None
            
            if current_gesture == "V_SIGN":
                # *** é”å±åŠŸèƒ½ (Vå­—æ‰‹åŠ¿) ***
                ctypes.windll.user32.LockWorkStation()
                action_performed = "é”å®šå±å¹• (API)"
                
            elif current_gesture == "OPEN_HAND":
                # *** çª—å£æœ€å¤§åŒ–åŠŸèƒ½ (å¼ å¼€æ‰‹æŒ) ***
                pyautogui.hotkey('win', 'up')
                action_performed = "çª—å£æœ€å¤§åŒ–"

            elif current_gesture == "CLOSED_FIST":
                # *** çª—å£ç¼©å°/æœ€å°åŒ–åŠŸèƒ½ (æ¡æ‹³) ***
                pyautogui.hotkey('win', 'down')
                action_performed = "çª—å£ç¼©å°/æœ€å°åŒ–"
            
            if action_performed:
                print(f"âœ… {current_gesture} -> {action_performed}")
                last_action_time = current_time
                gesture_detected = True
        
        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        display_text = f"GESTURE: {current_gesture}"
        mode_text = f"MODE: {'SCROLL' if scroll_mode_active else 'ACTIONS'}"
        
        cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        mode_y_pos = 90 if scroll_mode_active else 60
        cv2.putText(frame, mode_text, (10, mode_y_pos), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)


    # æ˜¾ç¤ºæœªæ£€æµ‹åˆ°æ‰‹çš„æç¤º
    if not results.multi_hand_landmarks:
         cv2.putText(frame, "No Hand Detected", (10, 30), 
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

    cv2.imshow('Robust Hand Gesture Control V11.0', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
hands.close()
print("æ‰‹åŠ¿æ§åˆ¶å·²é€€å‡ºã€‚")