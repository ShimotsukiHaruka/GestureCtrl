import cv2
import mediapipe as mp
import pyautogui
import time
import sys
import numpy as np
import math 
import ctypes 

# --- æ£€æŸ¥åº“æ˜¯å¦æ­£ç¡®å®‰è£… ---
try:
    print(f"OpenCV Version: {cv2.__version__}")
    print(f"MediaPipe Version: {mp.__version__}")
except AttributeError:
    print("ğŸ”´ é”™è¯¯ï¼šcv2 æˆ– mediapipe åº“æœªæ­£ç¡®åŠ è½½ï¼Œè¯·æ£€æŸ¥æ‚¨çš„ Python ç¯å¢ƒå’Œä¾èµ–ã€‚")
    sys.exit(1)

# --- åˆå§‹åŒ– MediaPipe ---
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(
    static_image_mode=False,
    max_num_hands=1,    # åªéœ€æ£€æµ‹ä¸€åªæ‰‹
    min_detection_confidence=0.7, 
    min_tracking_confidence=0.6 
)
mp_drawing = mp.solutions.drawing_utils

# --- åˆå§‹åŒ–æ‘„åƒå¤´ ---
cap = cv2.VideoCapture(0) 
if not cap.isOpened():
    print("ğŸ”´ é”™è¯¯ï¼šæ— æ³•æ‰“å¼€æ‘„åƒå¤´ã€‚")
    sys.exit(1)

# --- é…ç½®æ§åˆ¶å‚æ•° ---
COOLDOWN_TIME = 1.0     # çª—å£/ç³»ç»ŸåŠ¨ä½œå†·å´æ—¶é—´ï¼ˆç§’ï¼‰
CLICK_COOLDOWN_TIME = 0.3 # é¼ æ ‡ç‚¹å‡»çš„å†·å´æ—¶é—´
last_action_time = time.time() - COOLDOWN_TIME 
last_click_time = time.time() - CLICK_COOLDOWN_TIME

# é¼ æ ‡ç§»åŠ¨ç›¸å…³å‚æ•°
start_x, start_y = 0, 0     # ç›¸å¯¹ç§»åŠ¨é”šç‚¹
MOUSE_SENSITIVITY = 1.5     # é¼ æ ‡ç§»åŠ¨çµæ•åº¦

# æ ¸å¿ƒé˜ˆå€¼ï¼ˆè§’åº¦ï¼‰
STRAIGHT_ANGLE_THRESHOLD = 160 
BENT_ANGLE_THRESHOLD = 150     

# å››æŒ‡çš„å…³é”®ç‚¹åºåˆ—ï¼ˆMCP -> PIP -> TIPï¼‰
FINGER_JOINTS = [
    [5, 6, 8],    # é£ŸæŒ‡
    [9, 10, 12],  # ä¸­æŒ‡
    [13, 14, 16], # æ— åæŒ‡
    [17, 18, 20]  # å°æŒ‡
]

# --- æ ¸å¿ƒå‡½æ•°ï¼šè®¡ç®—ä¸‰ç‚¹å¤¹è§’ (ä¿æŒä¸å˜) ---
def calculate_angle(p1, p2, p3):
    p1_coords = np.array([p1.x, p1.y, p1.z])
    p2_coords = np.array([p2.x, p2.y, p2.z])
    p3_coords = np.array([p3.x, p3.y, p3.z])
    vec1 = p1_coords - p2_coords
    vec2 = p3_coords - p2_coords
    dot_product = np.dot(vec1, vec2)
    norm_product = np.linalg.norm(vec1) * np.linalg.norm(vec2)
    if norm_product == 0: return 180.0 
    cosine_angle = np.clip(dot_product / norm_product, -1.0, 1.0)
    angle_rad = np.arccos(cosine_angle)
    return np.degrees(angle_rad)

# --- æ ¸å¿ƒå‡½æ•°ï¼šåˆ¤æ–­æ‰‹æŒ‡çŠ¶æ€ (ä¿æŒä¸å˜) ---
def is_finger_straight(hand_landmarks, joints, threshold):
    p_mcp = hand_landmarks.landmark[joints[0]]
    p_pip = hand_landmarks.landmark[joints[1]]
    p_tip = hand_landmarks.landmark[joints[2]]
    angle = calculate_angle(p_mcp, p_pip, p_tip)
    return angle > threshold

# --- æ ¸å¿ƒæ‰‹åŠ¿è¯†åˆ«å‡½æ•°ï¼ˆV13.3 é€»è¾‘ï¼‰ ---
def get_hand_gesture(hand_landmarks):
    
    THUMB_CMC = mp_hands.HandLandmark.THUMB_CMC.value 
    THUMB_MP_INDEX = 2 
    THUMB_IP = mp_hands.HandLandmark.THUMB_IP.value 
    
    thumb_angle = calculate_angle(hand_landmarks.landmark[THUMB_CMC], hand_landmarks.landmark[THUMB_MP_INDEX], hand_landmarks.landmark[THUMB_IP])
    thumb_open = thumb_angle > BENT_ANGLE_THRESHOLD

    finger_states = []
    for joints in FINGER_JOINTS:
        is_open = is_finger_straight(hand_landmarks, joints, STRAIGHT_ANGLE_THRESHOLD)
        finger_states.append(is_open)

    index_open, middle_open, ring_open, pinky_open = finger_states

    four_fingers_closed = not index_open and not middle_open and not ring_open and not pinky_open
    all_fingers_open = [thumb_open, index_open, middle_open, ring_open, pinky_open]

    # --- æ‰‹åŠ¿é€»è¾‘åˆ¤æ–­ï¼ˆä¼˜å…ˆçº§ä»é«˜åˆ°ä½ï¼‰---
    
    # ğŸ“ L_SHAPE (L å½¢æ‰‹åŠ¿) -> é¼ æ ‡ç§»åŠ¨
    # é€»è¾‘ï¼šæ‹‡æŒ‡å’Œé£ŸæŒ‡ä¼¸ç›´
    if thumb_open and index_open and not middle_open and not ring_open and not pinky_open:
        return "L_SHAPE"
        
    # âœŠ CLOSE_HAND (å…¨æŒæ”¶æ‹¢/æ‹³å¤´) -> æœ€å°åŒ–
    elif not thumb_open and four_fingers_closed:
        return "CLOSE_HAND" 
    
    # âœ‹ OPEN_HAND (å¼ å¼€æ‰‹æŒ) -> æœ€å¤§åŒ–/æ¢å¤
    elif all(all_fingers_open):
        return "OPEN_HAND"
        
    # âœŒï¸ V_SIGN (å‰ªåˆ€æ‰‹) -> ä»»åŠ¡è§†å›¾
    elif not thumb_open and index_open and middle_open and not ring_open and not pinky_open:
        return "V_SIGN"
        
    # ğŸ‘† INDEX_FINGER (é£ŸæŒ‡æŒ‡å‘) -> é¼ æ ‡å·¦é”®ç‚¹å‡»
    # é€»è¾‘ï¼šä»…é£ŸæŒ‡ä¼¸ç›´ï¼Œå…¶ä»–å››æŒ‡æ”¶æ‹¢
    elif not thumb_open and index_open and not middle_open and not ring_open and not pinky_open:
        return "INDEX_FINGER"
        
    # ğŸ–• MIDDLE_FINGER (ä¸­æŒ‡æŒ‡å‘) -> é”å®šå±å¹•
    elif not thumb_open and not index_open and middle_open and not ring_open and not pinky_open:
        return "MIDDLE_FINGER"
        
    # THUMB_UP é€»è¾‘å·²ç§»é™¤

    return "UNKNOWN"

# --- æ ¸å¿ƒå‡½æ•°ï¼šç›¸å¯¹é¼ æ ‡ç§»åŠ¨æ§åˆ¶ ---
def control_mouse_by_relative_movement(hand_landmarks, frame_width, frame_height):
    """
    æ ¹æ® L å½¢æ‰‹åŠ¿ä¸­é£ŸæŒ‡å°–çš„ç›¸å¯¹ä½ç§»æ§åˆ¶é¼ æ ‡ã€‚
    """
    global start_x, start_y, MOUSE_SENSITIVITY
    
    # ä½¿ç”¨é£ŸæŒ‡å°–ä½œä¸ºç§»åŠ¨é”šç‚¹
    index_finger_tip = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP.value]
    current_x = index_finger_tip.x
    current_y = index_finger_tip.y
    
    if start_x == 0 and start_y == 0:
        # ç¬¬ä¸€æ¬¡æ£€æµ‹åˆ° L_SHAPEï¼Œè®¾ç½®é”šç‚¹
        start_x, start_y = current_x, current_y
        return "READY" 

    dx = current_x - start_x
    dy = current_y - start_y
    
    # å°†å½’ä¸€åŒ–ä½ç§»æ˜ å°„åˆ°å±å¹•åƒç´ ä½ç§»
    move_x = int(dx * frame_width * MOUSE_SENSITIVITY)
    move_y = int(dy * frame_height * MOUSE_SENSITIVITY) 

    # åªæœ‰å½“ç§»åŠ¨é‡å¤§äºå¾®å°é˜ˆå€¼æ—¶æ‰ç§»åŠ¨
    if abs(move_x) > 1 or abs(move_y) > 1:
        pyautogui.move(move_x, move_y)
        # æ›´æ–°é”šç‚¹ï¼Œä¿æŒç›¸å¯¹ç§»åŠ¨
        start_x, start_y = current_x, current_y 
        return "MOVING"
    else:
        return "STILL"


# --- ä¸»å¾ªç¯ ---
print("=== V13.3 æœ€ç»ˆç²¾ç®€ç‰ˆæ‰‹åŠ¿æ§åˆ¶ç³»ç»Ÿ ===")
print("æ‰‹åŠ¿åŠŸèƒ½è¯´æ˜ï¼š")
print("ğŸ“ Lå½¢æ‰‹åŠ¿ -> **ä¸»å¯¼å…‰æ ‡ç§»åŠ¨**")
print("ğŸ‘† é£ŸæŒ‡æŒ‡å‘ -> **é¼ æ ‡å·¦é”®ç‚¹å‡»**")
print("âœŒï¸ å‰ªåˆ€æ‰‹ -> æ¢å¤æ‰€æœ‰çª—å£ (Win+Tab)")
print("âœ‹ å…¨æŒ -> çª—å£æœ€å¤§åŒ– (Win+Up)")
print("âœŠ æ‹³å¤´ -> çª—å£ç¼©å°/æœ€å°åŒ– (Win+Down)")
print("ğŸ–• ä¸­æŒ‡æŒ‡å‘ -> é”å®šå±å¹• (Win API)")
print("åœ¨è§†é¢‘çª—å£ä¸­æŒ‰ 'q' é”®é€€å‡ºã€‚")

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame = cv2.flip(frame, 1) # é•œåƒç¿»è½¬
    rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    
    results = hands.process(rgb_frame)
    current_time = time.time()
    
    hand_landmarks_list = results.multi_hand_landmarks if results.multi_hand_landmarks else []
    
    if hand_landmarks_list:
        frame_height, frame_width, _ = frame.shape
        hand_landmarks = hand_landmarks_list[0] 
        mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)
            
        current_gesture = get_hand_gesture(hand_landmarks)

        # é»˜è®¤ä¸ºç©ºæ“ä½œ
        display_action = ""
        action_performed = None

        # --- A. é¼ æ ‡ç§»åŠ¨/ç‚¹å‡»é€»è¾‘ (L_SHAPE å’Œ INDEX_FINGER) ---
        if current_gesture == "L_SHAPE":
            # Lå½¢æ‰‹åŠ¿ï¼šç›¸å¯¹å…‰æ ‡ç§»åŠ¨
            move_state = control_mouse_by_relative_movement(hand_landmarks, frame_width, frame_height)
            display_action = f"MOUSE: {move_state}"
            
        elif current_gesture == "INDEX_FINGER":
            # é£ŸæŒ‡æŒ‡å‘ï¼šé¼ æ ‡å·¦é”®ç‚¹å‡»
            if current_time - last_click_time > CLICK_COOLDOWN_TIME:
                 pyautogui.click()
                 last_click_time = current_time
                 display_action = "MOUSE: LEFT CLICK"
            else:
                 display_action = "MOUSE: CLICK COOLDOWN"
            
        else:
            # éç§»åŠ¨æ‰‹åŠ¿æ—¶ï¼Œé‡ç½®é”šç‚¹ï¼Œé˜²æ­¢å…‰æ ‡è·³è·ƒ
            start_x, start_y = 0, 0 
            
            # --- B. çª—å£/ç³»ç»ŸåŠ¨ä½œé€»è¾‘ (ACTIONS) ---
            if current_time - last_action_time > COOLDOWN_TIME:
                
                # âœŒï¸ V_SIGN (å‰ªåˆ€æ‰‹) -> æ¢å¤æ‰€æœ‰å·²æ‰“å¼€çª—å£ (Task View)
                if current_gesture == "V_SIGN": 
                    pyautogui.hotkey('win', 'tab')
                    action_performed = "æ¢å¤æ‰€æœ‰çª—å£ (Task View)"
                    
                # âœ‹ OPEN_HAND (å¼ å¼€æ‰‹æŒ) -> æœ€å¤§åŒ–
                elif current_gesture == "OPEN_HAND":
                    pyautogui.hotkey('win', 'up')
                    action_performed = "çª—å£æœ€å¤§åŒ–"

                # âœŠ CLOSE_HAND (æ‹³å¤´) -> æœ€å°åŒ–
                elif current_gesture == "CLOSE_HAND": 
                    pyautogui.hotkey('win', 'down')
                    action_performed = "çª—å£ç¼©å°/æœ€å°åŒ–"
                
                # ğŸ–• MIDDLE_FINGER (ä¸­æŒ‡æŒ‡å‘) -> é”å®šå±å¹•
                elif current_gesture == "MIDDLE_FINGER":
                    ctypes.windll.user32.LockWorkStation()
                    action_performed = "é”å®šå±å¹• (API)"
                
                if action_performed:
                    print(f"âœ… {current_gesture} -> {action_performed}")
                    last_action_time = current_time

        # æ˜¾ç¤ºå½“å‰çŠ¶æ€
        display_text = f"GESTURE: {current_gesture}"
        cv2.putText(frame, display_text, (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
        cv2.putText(frame, display_action, (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 165, 0), 2)


    # --- 2. æœªæ£€æµ‹åˆ°æ‰‹çš„æç¤º ---
    if not results.multi_hand_landmarks:
          cv2.putText(frame, "No Hand Detected", (10, 30), 
                      cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
          # ä¸¢å¤±æ‰‹éƒ¨æ—¶ï¼Œé‡ç½®å…‰æ ‡é”šç‚¹
          start_x, start_y = 0, 0

    cv2.imshow('Hand Gesture Control V13.3 (Minimal Single Mode)', frame)

    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

# --- èµ„æºé‡Šæ”¾ ---
cap.release()
cv2.destroyAllWindows()
hands.close()
print("æ‰‹åŠ¿æ§åˆ¶å·²é€€å‡ºã€‚")